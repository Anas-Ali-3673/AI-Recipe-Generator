{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5093016,"sourceType":"datasetVersion","datasetId":2957522}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:12:43.891401Z","iopub.execute_input":"2025-11-03T21:12:43.892080Z","iopub.status.idle":"2025-11-03T21:12:43.898411Z","shell.execute_reply.started":"2025-11-03T21:12:43.892053Z","shell.execute_reply":"2025-11-03T21:12:43.897566Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/3a2mext/3A2M_EXTENDED.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Install all required packages\n!pip install transformers datasets accelerate rouge-score nltk -q\n\n# Download NLTK data for BLEU score\nimport nltk\nnltk.download('punkt')\nnltk.download('punkt_tab')\n\nprint(\"✅ All packages installed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T22:02:08.068006Z","iopub.execute_input":"2025-11-03T22:02:08.068577Z","iopub.status.idle":"2025-11-03T22:02:12.532701Z","shell.execute_reply.started":"2025-11-03T22:02:08.068558Z","shell.execute_reply":"2025-11-03T22:02:12.531875Z"}},"outputs":[{"name":"stdout","text":"✅ All packages installed successfully!\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Recipe Generation using GPT-2 - Data Preparation\n# This script prepares the recipe dataset for fine-tuning\n\nimport pandas as pd\nimport json\nimport os\nimport ast\nfrom datasets import Dataset\nfrom transformers import GPT2Tokenizer\nfrom sklearn.model_selection import train_test_split\n\n# Dataset path\ndataset_path = '/kaggle/input/3a2mext/3A2M_EXTENDED.csv'\n\n# Load the dataset\nprint(\"Loading dataset...\")\ndf = pd.read_csv(dataset_path)\n\n# Display basic info\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {df.columns.tolist()}\")\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\n# Clean the data\n# The dataset uses 'NER' for ingredients\ndf = df.dropna(subset=['title', 'NER', 'directions'])\nprint(f\"\\nDataset shape after removing nulls: {df.shape}\")\n\n# Function to clean and parse ingredients\ndef parse_ingredients(ing_str):\n    \"\"\"Convert string representation of list to actual list\"\"\"\n    try:\n        # Parse the string as a Python list\n        ing_list = ast.literal_eval(ing_str)\n        # Join ingredients with commas\n        return ', '.join(ing_list)\n    except:\n        return ing_str\n\n# Function to clean and parse directions\ndef parse_directions(dir_str):\n    \"\"\"Convert string representation of list to actual list\"\"\"\n    try:\n        # Parse the string as a Python list\n        dir_list = ast.literal_eval(dir_str)\n        # Join directions with numbered steps\n        steps = [f\"{i+1}. {step}\" for i, step in enumerate(dir_list)]\n        return ' '.join(steps)\n    except:\n        return dir_str\n\n# Clean title (remove \\t if present)\ndf['title'] = df['title'].str.strip()\n\n# Parse ingredients and directions\nprint(\"\\nParsing ingredients and directions...\")\ndf['ingredients_clean'] = df['NER'].apply(parse_ingredients)\ndf['directions_clean'] = df['directions'].apply(parse_directions)\n\n# Function to format recipe into text format for GPT-2\ndef format_recipe(row):\n    \"\"\"\n    Format: \n    Recipe: [title]\n    Ingredients: [ingredients]\n    Instructions: [directions]\n    \"\"\"\n    text = f\"Recipe: {row['title']}\\n\"\n    text += f\"Ingredients: {row['ingredients_clean']}\\n\"\n    text += f\"Instructions: {row['directions_clean']}\\n\"\n    text += \"<|endoftext|>\"  # Special token to mark end\n    return text\n\n# Create formatted text column\nprint(\"Formatting recipes...\")\ndf['text'] = df.apply(format_recipe, axis=1)\n\n# Show example\nprint(\"\\nExample formatted recipe:\")\nprint(\"=\"*60)\nprint(df['text'].iloc[0][:800])\nprint(\"=\"*60)\n\n# Remove extremely long or short recipes\ndf['text_length'] = df['text'].apply(len)\nprint(f\"\\nText length statistics:\")\nprint(df['text_length'].describe())\n\n# Filter recipes between 100 and 2000 characters\ndf = df[(df['text_length'] > 100) & (df['text_length'] < 2000)]\nprint(f\"Dataset shape after length filtering: {df.shape}\")\n\n# Use a sample for faster training (student project)\n# Adjust this based on your computational resources\nsample_size = 10000  # Start with 10k, reduce if needed\n\nif len(df) > sample_size:\n    df = df.sample(n=sample_size, random_state=42)\n    print(f\"\\nUsing {sample_size} samples for training\")\nelse:\n    print(f\"\\nUsing all {len(df)} samples\")\n\n# Split into train and validation sets\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\nprint(f\"\\nTraining samples: {len(train_df)}\")\nprint(f\"Validation samples: {len(val_df)}\")\n\n# Save processed data\ntrain_df[['text']].to_csv('train_recipes.csv', index=False)\nval_df[['text']].to_csv('val_recipes.csv', index=False)\n\n# Also save a few examples for reference\nexamples_df = train_df[['title', 'ingredients_clean', 'directions_clean', 'text']].head(10)\nexamples_df.to_csv('recipe_examples.csv', index=False)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Data preparation complete!\")\nprint(\"=\"*60)\nprint(\"\\nSaved files:\")\nprint(\"- train_recipes.csv\")\nprint(\"- val_recipes.csv\")\nprint(\"- recipe_examples.csv\")\n\nprint(\"\\nDataset statistics:\")\nprint(f\"Total recipes processed: {len(df)}\")\nprint(f\"Training set: {len(train_df)}\")\nprint(f\"Validation set: {len(val_df)}\")\nprint(f\"Average recipe length: {df['text_length'].mean():.0f} characters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:16:51.972822Z","iopub.execute_input":"2025-11-03T21:16:51.973552Z","iopub.status.idle":"2025-11-03T21:19:11.150795Z","shell.execute_reply.started":"2025-11-03T21:16:51.973526Z","shell.execute_reply":"2025-11-03T21:19:11.150072Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nDataset shape: (2231143, 6)\nColumns: ['title', 'NER', 'Extended_NER', 'genre', 'label', 'directions']\n\nFirst few rows:\n                                         title  \\\n0                 \\t Arugula Pomegranate Salad   \n1               \\t Black Bean And Turkey Chili   \n2               \\t Finger Lickin' Tofu Nuggets   \n3  \\t Jerk Beef Stew With Carrots And Tomatoes   \n4                \\t Pomegranate Couscous Salad   \n\n                                                 NER  \\\n0  [\"baby spinach\", \"baby arugula\", \"pomegranate ...   \n1  [\"olive oil\", \"yellow onion\", \"garlic\", \"groun...   \n2  [\"extra firm\", \"almond flour\", \"nutritional ye...   \n3  [\"olive oil\", \"boneless beef chuck\", \"onion\", ...   \n4  [\"pomegranate arils\", \"whole wheat couscous\", ...   \n\n                                        Extended_NER       genre  label  \\\n0  ['alfalfa sprouts', 'baby spinach', 'baby arug...  vegetables      4   \n1  ['one', 'yellow onion', 'tomato paste', 'about...       sides      8   \n2  ['extra firm', '2', 'coconut oil', 'almond flo...      nonveg      3   \n3  ['boneless beef chuck', '2', 'Saute', 'onion',...  vegetables      4   \n4  ['whole wheat couscous', '10 minutes', 'lemon ...  vegetables      4   \n\n                                          directions  \n0  [\"Toss together spinach and arugula, then plac...  \n1  [\"Dice the onion and mince the garlic. Add the...  \n2  [\"Wrap the tofu in a clean tea towel and press...  \n3  [\"Preheat oven to 350 degrees F.\", \"Heat the o...  \n4  [\"Place couscous in a bowl with 11/2 cups of h...  \n\nMissing values:\ntitle           1\nNER             0\nExtended_NER    0\ngenre           0\nlabel           0\ndirections      0\ndtype: int64\n\nDataset shape after removing nulls: (2231142, 6)\n\nParsing ingredients and directions...\nFormatting recipes...\n\nExample formatted recipe:\n============================================================\nRecipe: Arugula Pomegranate Salad\nIngredients: baby spinach, baby arugula, pomegranate arils, persimmon, alfalfa sprouts\nInstructions: 1. Toss together spinach and arugula, then place in your serving bowl. 2. Remove the stem and leaves of the persimmon, then slice into thin wedges. 3. Arrange the persimmon on top of the spinach and arugula. 4. Garnish with pomegranate arils and alfalfa sprouts.\n<|endoftext|>\n============================================================\n\nText length statistics:\ncount    2.231142e+06\nmean     6.694110e+02\nstd      4.818798e+02\nmin      6.300000e+01\n25%      3.610000e+02\n50%      5.250000e+02\n75%      8.230000e+02\nmax      1.545700e+04\nName: text_length, dtype: float64\nDataset shape after length filtering: (2181174, 10)\n\nUsing 10000 samples for training\n\nTraining samples: 9000\nValidation samples: 1000\n\n============================================================\nData preparation complete!\n============================================================\n\nSaved files:\n- train_recipes.csv\n- val_recipes.csv\n- recipe_examples.csv\n\nDataset statistics:\nTotal recipes processed: 10000\nTraining set: 9000\nValidation set: 1000\nAverage recipe length: 628 characters\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# GPT-2 Fine-tuning for Recipe Generation\n# Training Script\n\nimport pandas as pd\nimport torch\nfrom transformers import (\n    GPT2LMHeadModel, \n    GPT2Tokenizer, \n    Trainer, \n    TrainingArguments,\n    DataCollatorForLanguageModeling\n)\nfrom datasets import Dataset\n\n# Check if GPU is available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Load tokenizer and model\nprint(\"\\nLoading GPT-2 model and tokenizer...\")\nmodel_name = \"gpt2\"  # You can also try \"gpt2-medium\" if you have more resources\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n\n# Set padding token (GPT-2 doesn't have one by default)\ntokenizer.pad_token = tokenizer.eos_token\nmodel.config.pad_token_id = tokenizer.eos_token_id\n\nprint(f\"Model loaded: {model_name}\")\nprint(f\"Vocab size: {len(tokenizer)}\")\n\n# Load prepared data\nprint(\"\\nLoading prepared datasets...\")\ntrain_df = pd.read_csv('train_recipes.csv')\nval_df = pd.read_csv('val_recipes.csv')\n\n# Convert to HuggingFace Dataset format\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\n# Tokenization function\ndef tokenize_function(examples):\n    \"\"\"Tokenize the text data\"\"\"\n    return tokenizer(\n        examples['text'],\n        truncation=True,\n        max_length=512,  # Adjust based on your recipes length\n        padding='max_length'\n    )\n\n# Tokenize datasets\nprint(\"\\nTokenizing datasets...\")\ntokenized_train = train_dataset.map(\n    tokenize_function, \n    batched=True,\n    remove_columns=['text']\n)\ntokenized_val = val_dataset.map(\n    tokenize_function, \n    batched=True,\n    remove_columns=['text']\n)\n\nprint(\"Tokenization complete!\")\n\n# Data collator for language modeling\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False  # GPT-2 uses causal language modeling, not masked\n)\n\n# Training arguments - adjusted for student project on Kaggle\ntraining_args = TrainingArguments(\n    output_dir='./recipe-gpt2-finetuned',\n    overwrite_output_dir=True,\n    num_train_epochs=3,  # Start with 3, can increase if needed\n    per_device_train_batch_size=4,  # Adjust based on GPU memory\n    per_device_eval_batch_size=4,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy='steps',\n    eval_steps=500,\n    save_steps=1000,\n    save_total_limit=2,  # Only keep 2 best checkpoints to save space\n    prediction_loss_only=True,\n    report_to='none',  # Disable wandb/tensorboard for simplicity\n    fp16=True if device == 'cuda' else False,  # Use mixed precision on GPU\n)\n\nprint(\"\\nTraining Arguments:\")\nprint(f\"Epochs: {training_args.num_train_epochs}\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"Learning rate: {training_args.learning_rate}\")\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n)\n\n# Start training\nprint(\"\\n\" + \"=\"*50)\nprint(\"Starting training...\")\nprint(\"=\"*50 + \"\\n\")\n\ntrainer.train()\n\n# Save the final model\nprint(\"\\nSaving model...\")\ntrainer.save_model('./recipe-gpt2-final')\ntokenizer.save_pretrained('./recipe-gpt2-final')\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training complete!\")\nprint(\"Model saved to: ./recipe-gpt2-final\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:20:01.961436Z","iopub.execute_input":"2025-11-03T21:20:01.962079Z","iopub.status.idle":"2025-11-03T21:58:05.576535Z","shell.execute_reply.started":"2025-11-03T21:20:01.962054Z","shell.execute_reply":"2025-11-03T21:58:05.575832Z"}},"outputs":[{"name":"stderr","text":"2025-11-03 21:20:13.209283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762204813.634726      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762204813.756690      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n\nLoading GPT-2 model and tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fefc35aa9d94a3baa051d391e4519d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7d7e9871da4c8b8afa79cd9a287a4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df0b9afe4914f479ce5329378f3e8f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36a988b090c546379c2d43be1f682965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7519103b7b04d59966c1a6a2642f1ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c39633302674b7784fc9005639aa83e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e950ca36ee1a4dcc86932a39560595e3"}},"metadata":{}},{"name":"stdout","text":"Model loaded: gpt2\nVocab size: 50257\n\nLoading prepared datasets...\n\nTokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceabe5098cec4c658a2bef276cedf8e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"170bde6caf7b431b99dad3dc93d5727c"}},"metadata":{}},{"name":"stdout","text":"Tokenization complete!\n\nTraining Arguments:\nEpochs: 3\nBatch size: 4\nLearning rate: 5e-05\n\n==================================================\nStarting training...\n==================================================\n\n","output_type":"stream"},{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3375' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3375/3375 37:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.244200</td>\n      <td>2.316139</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.201700</td>\n      <td>2.233753</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.133100</td>\n      <td>2.186581</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.089900</td>\n      <td>2.152513</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.051700</td>\n      <td>2.129192</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.071300</td>\n      <td>2.121942</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nSaving model...\n\n==================================================\nTraining complete!\nModel saved to: ./recipe-gpt2-final\n==================================================\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Testing and Evaluation Script for Fine-tuned Recipe GPT-2\n\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom rouge_score import rouge_scorer\nimport pandas as pd\nimport numpy as np\n\n# Load the fine-tuned model\nprint(\"Loading fine-tuned model...\")\nmodel_path = './recipe-gpt2-final'\ntokenizer = GPT2Tokenizer.from_pretrained(model_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\nmodel.eval()\n\nprint(f\"Model loaded on {device}\")\n\n# Function to generate recipe\ndef generate_recipe(prompt, max_length=300, temperature=0.8, top_p=0.9):\n    \"\"\"\n    Generate a recipe given a prompt\n    \n    Args:\n        prompt: Starting text (e.g., \"Recipe: Chocolate Cake\")\n        max_length: Maximum tokens to generate\n        temperature: Controls randomness (higher = more random)\n        top_p: Nucleus sampling parameter\n    \"\"\"\n    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n    \n    with torch.no_grad():\n        output = model.generate(\n            input_ids,\n            max_length=max_length,\n            temperature=temperature,\n            top_p=top_p,\n            do_sample=True,\n            pad_token_id=tokenizer.eos_token_id,\n            num_return_sequences=1\n        )\n    \n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n\n# Test examples\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING RECIPE GENERATION\")\nprint(\"=\"*60)\n\n# Example 1: Generate from dish name\nprint(\"\\n--- Example 1: Chocolate Cake ---\")\nprompt1 = \"Recipe: Chocolate Cake\\nIngredients:\"\nrecipe1 = generate_recipe(prompt1)\nprint(recipe1)\n\n# Example 2: Generate from ingredients\nprint(\"\\n--- Example 2: Chicken with vegetables ---\")\nprompt2 = \"Recipe: Grilled Chicken\\nIngredients:\"\nrecipe2 = generate_recipe(prompt2)\nprint(recipe2)\n\n# Example 3: Another dish\nprint(\"\\n--- Example 3: Pasta ---\")\nprompt3 = \"Recipe: Spaghetti Carbonara\\nIngredients:\"\nrecipe3 = generate_recipe(prompt3)\nprint(recipe3)\n\n# Example 4: Custom ingredients\nprint(\"\\n--- Example 4: From ingredients ---\")\nprompt4 = \"Recipe: Vegetable Stir Fry\\nIngredients: broccoli, carrots, soy sauce, garlic\\nInstructions:\"\nrecipe4 = generate_recipe(prompt4, max_length=200)\nprint(recipe4)\n\n# Evaluation metrics\nprint(\"\\n\" + \"=\"*60)\nprint(\"EVALUATION METRICS\")\nprint(\"=\"*60)\n\n# Load validation data for evaluation\nval_df = pd.read_csv('val_recipes.csv')\nsample_recipes = val_df.sample(n=10, random_state=42)\n\n# Initialize rouge scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nbleu_scores = []\nrouge_scores = []\n\nprint(\"\\nCalculating BLEU and ROUGE scores on validation samples...\")\nprint(\"This may take a few minutes...\\n\")\n\nfor idx, (i, row) in enumerate(sample_recipes.iterrows()):\n    print(f\"Evaluating sample {idx+1}/10...\", end='\\r')\n    \n    # Extract prompt from original recipe\n    original = row['text']\n    \n    # Get first line as prompt\n    lines = original.split('\\n')\n    if len(lines) > 0:\n        prompt = lines[0] + \"\\nIngredients:\"\n    else:\n        continue\n    \n    # Generate recipe\n    generated = generate_recipe(prompt, max_length=300, temperature=0.7)\n    \n    # Calculate BLEU score\n    reference = [original.split()]\n    candidate = generated.split()\n    smoothie = SmoothingFunction().method4\n    bleu = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n    bleu_scores.append(bleu)\n    \n    # Calculate ROUGE scores using rouge_score package\n    try:\n        scores = scorer.score(original, generated)\n        rouge_scores.append(scores['rougeL'].fmeasure)\n    except:\n        pass\n\nprint(\"\\n\")  # New line after progress\n\n# Print results\nif bleu_scores:\n    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n    print(f\"\\nAverage BLEU Score: {avg_bleu:.4f}\")\n\nif rouge_scores:\n    avg_rouge = sum(rouge_scores) / len(rouge_scores)\n    print(f\"Average ROUGE-L F1 Score: {avg_rouge:.4f}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Evaluation complete!\")\nprint(\"=\"*60)\n\n# Save sample generations\nprint(\"\\nSaving sample generations...\")\nexamples = {\n    'Prompt': [\n        \"Recipe: Chocolate Cake\",\n        \"Recipe: Grilled Chicken\", \n        \"Recipe: Spaghetti Carbonara\",\n        \"Recipe: Vegetable Stir Fry\"\n    ],\n    'Generated Recipe': [recipe1, recipe2, recipe3, recipe4]\n}\n\nresults_df = pd.DataFrame(examples)\nresults_df.to_csv('generated_recipes_examples.csv', index=False)\nprint(\"Saved to: generated_recipes_examples.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T22:05:22.838827Z","iopub.execute_input":"2025-11-03T22:05:22.839162Z","iopub.status.idle":"2025-11-03T22:06:02.101224Z","shell.execute_reply.started":"2025-11-03T22:05:22.839140Z","shell.execute_reply":"2025-11-03T22:06:02.100547Z"}},"outputs":[{"name":"stdout","text":"Loading fine-tuned model...\nModel loaded on cuda\n\n============================================================\nTESTING RECIPE GENERATION\n============================================================\n\n--- Example 1: Chocolate Cake ---\nRecipe: Chocolate Cake\nIngredients: shortening, sugar, baking soda, salt, cake flour, brown sugar, butter, egg whites, chocolate, sugar, vanilla, eggs, milk, baking powder, cinnamon, nutmeg, buttermilk, coconut, nuts\nInstructions: 1. In a bowl, whisk together shortening, sugar, baking soda, salt, baking soda, and nutmeg. 2. Add eggs, milk, baking powder, cinnamon, nutmeg, buttermilk, coconut, nuts, and vanilla. 3. Mix well. 4. Stir in nuts. 5. Fold in remaining ingredients. 6. Bake at 350° for 1 hour.\nNutritional Information: Calories: Fat: 2.5 g, cholesterol: 2.5 g, sodium: 1 g, cholesterol: 3 g, saturated fat: 1 g, cholesterol: 2.5 g, cholesterol: 4.5 g\nIngredients: flour, cocoa, milk, cocoa powder, baking powder, cinnamon, nutmeg, buttermilk, coconut, nuts, coconut, chocolate, sugar, vanilla, eggs, milk, baking powder, cinnamon, nutmeg, buttermilk, coconut, nuts, coconut, almonds, walnuts, walnuts\nInstructions: 1. In a medium bowl, combine butter, sugar, egg whites, chocolate, and vanilla. 2. Fold in almond extract. 3. Set aside. 4. Combine flour, cocoa, and sugar. 5. Fold\n\n--- Example 2: Chicken with vegetables ---\nRecipe: Grilled Chicken\nIngredients: chicken breasts, mayonnaise, mustard, mayonnaise, Parmesan cheese, onion, salt, pepper, pepper\nInstructions: 1. Mix together the chicken breasts, mayonnaise, mustard, and mayonnaise. 2. Mix together the mayonnaise, mustard, and pepper. 3. Pour into a large skillet and cook on high heat for 3 to 5 minutes or until chicken is browned and cooked through. 4. Remove chicken from heat and pour into a baking dish and drizzle with Parmesan cheese and sprinkle with salt and pepper. 5. Bake at 375° for 30 minutes or until golden brown.\nNote: 1. Use extra virgin olive oil to cook the chicken. 2. Heat the oven to 350°. 3. In a large skillet, brown the chicken breasts in the butter over medium heat. 4. Add the onion and cook until softened and translucent, about 1 minute. 5. Add the garlic and cook, stirring, until the garlic is softened and the garlic is fragrant, about 5 minutes. 6. Add the chicken and cook, stirring, until the chicken is lightly browned, about 5 minutes. 7. Add the tomato sauce and cook, stirring, until the tomatoes are tender, about 2 minutes. 8. Add the chicken mixture, tomatoes, and sauce to the chicken mixture. 9. Cook for 2 to 3 minutes longer or until chicken is cooked through. 10. Serve warm or\n\n--- Example 3: Pasta ---\nRecipe: Spaghetti Carbonara\nIngredients: spaghetti, onions, tomato, cream of celery soup, salt, pepper, Italian seasoning\nInstructions: 1. Heat oven to 425 degrees F (175 degrees C). 2. Add onion and cook until soft, about 3 minutes. 3. Add soup, tomato sauce and salt; cook 5 minutes more or until tomato is tender. 4. Add spaghetti mixture and mix well. 5. Add noodles; mix well. 6. Spoon spaghetti mixture into a large, greased baking dish. 7. Bake until spaghetti is cooked through, about 5 minutes. 8. Stir in remaining ingredients; bake, uncovered, for 10 minutes or until heated through. 9. Serve with crackers.\nIngredients: noodles, cheese, spaghetti sauce, fresh basil, tomatoes\nInstructions: 1. In a large saucepan, combine soup, soup, sauce, noodles, cheese and spaghetti sauce. Bring to a boil. 2. Reduce heat to low; simmer, covered, 20 minutes. 3. Remove from heat. 4. Stir in remaining ingredients; simmer for 20 minutes or until sauce thickens. 5. Sprinkle crackers with cracker crumbs. 6. Serve with crackers.\nInstructions: 1. In a large skillet, heat 1 tablespoon olive oil over medium-high heat. 2. Add crackers; cook for 2 minutes or until crackers are softened. 3. Add Italian seasoning; cook 1 minute longer or until crack\n\n--- Example 4: From ingredients ---\nRecipe: Vegetable Stir Fry\nIngredients: broccoli, carrots, soy sauce, garlic\nInstructions: 1. Combine broccoli, carrots, soy sauce, garlic and salt in large bowl. 2. Cover and cook 5 minutes or until veggies are tender. 3. Drain on paper towels. 4. Stir in tofu, if desired. 5. Top with more soy sauce.\n(Can also use fresh spinach, if desired.)\n(Can be made in 12-inch skillet.)\nInstructions: 1. In a medium saucepan, bring water to boil. 2. Reduce heat. 3. Cook 3 minutes or until vegetables are tender. 4. Stir in spinach. 5. Stir in tofu. 6. Cover and simmer 20 minutes or until spinach is tender. 7. Stir in tofu. 8. Add additional soy sauce. 9. Cook until tofu is almost tender. 10. Stir in tofu mixture. 11. Serve over rice.\n(Can also be made in 12-inch\n\n============================================================\nEVALUATION METRICS\n============================================================\n\nCalculating BLEU and ROUGE scores on validation samples...\nThis may take a few minutes...\n\nEvaluating sample 10/10...\n\n\nAverage BLEU Score: 0.0384\nAverage ROUGE-L F1 Score: 0.1862\n\n============================================================\nEvaluation complete!\n============================================================\n\nSaving sample generations...\nSaved to: generated_recipes_examples.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Improved Recipe Generation Script\n# This version adds better generation controls and post-processing\n\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport pandas as pd\n\n# Load the fine-tuned model\nprint(\"Loading fine-tuned model...\")\nmodel_path = './recipe-gpt2-final'\ntokenizer = GPT2Tokenizer.from_pretrained(model_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\nmodel.eval()\n\nprint(f\"Model loaded on {device}\")\n\n# Improved generation function\ndef generate_recipe_improved(prompt, max_length=400, temperature=0.7, \n                            top_p=0.9, top_k=50, repetition_penalty=1.2):\n    \"\"\"\n    Generate recipe with improved parameters to reduce repetition\n    \n    Args:\n        prompt: Starting text\n        max_length: Maximum tokens\n        temperature: Randomness (0.7 = more focused, 0.9 = more creative)\n        top_p: Nucleus sampling\n        top_k: Top-k sampling\n        repetition_penalty: Penalty for repeating tokens (>1.0 reduces repetition)\n    \"\"\"\n    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n    \n    # Create attention mask\n    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=device)\n    \n    with torch.no_grad():\n        output = model.generate(\n            input_ids,\n            attention_mask=attention_mask,\n            max_length=max_length,\n            temperature=temperature,\n            top_p=top_p,\n            top_k=top_k,\n            repetition_penalty=repetition_penalty,\n            do_sample=True,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n            num_return_sequences=1,\n            no_repeat_ngram_size=3  # Prevent 3-gram repetition\n        )\n    \n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    \n    # Post-process: Stop at natural ending\n    # Look for second occurrence of \"Recipe:\" or end token\n    lines = generated_text.split('\\n')\n    clean_lines = []\n    recipe_count = 0\n    \n    for line in lines:\n        if line.strip().startswith('Recipe:'):\n            recipe_count += 1\n            if recipe_count > 1:  # Stop at second recipe\n                break\n        clean_lines.append(line)\n    \n    return '\\n'.join(clean_lines)\n\n# Test with different parameter settings\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING IMPROVED GENERATION\")\nprint(\"=\"*60)\n\n# Example 1: More focused (lower temperature)\nprint(\"\\n--- Example 1: Chocolate Cake (Focused) ---\")\nprompt1 = \"Recipe: Chocolate Cake\\nIngredients:\"\nrecipe1 = generate_recipe_improved(prompt1, temperature=0.7, repetition_penalty=1.3)\nprint(recipe1)\n\n# Example 2: More creative (higher temperature)\nprint(\"\\n--- Example 2: Thai Curry (Creative) ---\")\nprompt2 = \"Recipe: Thai Green Curry\\nIngredients:\"\nrecipe2 = generate_recipe_improved(prompt2, temperature=0.85, repetition_penalty=1.2)\nprint(recipe2)\n\n# Example 3: From ingredients\nprint(\"\\n--- Example 3: From Ingredients ---\")\nprompt3 = \"Recipe: Healthy Breakfast Bowl\\nIngredients: oats, banana, honey, almonds, berries\\nInstructions:\"\nrecipe3 = generate_recipe_improved(prompt3, temperature=0.75, max_length=300)\nprint(recipe3)\n\n# Generate multiple variations\nprint(\"\\n\" + \"=\"*60)\nprint(\"GENERATING VARIATIONS\")\nprint(\"=\"*60)\n\ndef generate_variations(prompt, n=3):\n    \"\"\"Generate n variations of the same recipe\"\"\"\n    print(f\"\\nGenerating {n} variations for: {prompt}\\n\")\n    variations = []\n    \n    for i in range(n):\n        print(f\"Variation {i+1}:\")\n        print(\"-\" * 40)\n        # Use different temperatures for variety\n        temp = 0.7 + (i * 0.1)\n        recipe = generate_recipe_improved(prompt, temperature=temp, repetition_penalty=1.2)\n        variations.append(recipe)\n        print(recipe)\n        print()\n    \n    return variations\n\n# Test variations\nprompt = \"Recipe: Vegetable Soup\\nIngredients:\"\nvariations = generate_variations(prompt, n=3)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"QUALITY ANALYSIS\")\nprint(\"=\"*60)\n\n# Simple quality metrics\ndef analyze_quality(recipe_text):\n    \"\"\"Analyze basic quality metrics\"\"\"\n    lines = recipe_text.split('\\n')\n    \n    # Count sections\n    has_ingredients = any('Ingredients:' in line for line in lines)\n    has_instructions = any('Instructions:' in line for line in lines)\n    \n    # Count ingredients and steps\n    ingredient_count = len([l for l in lines if l.strip() and 'Ingredients:' not in l and 'Instructions:' not in l and 'Recipe:' not in l and not l[0].isdigit()])\n    step_count = len([l for l in lines if l.strip() and l[0].isdigit()])\n    \n    # Check repetition\n    words = recipe_text.lower().split()\n    unique_ratio = len(set(words)) / len(words) if words else 0\n    \n    return {\n        'has_ingredients': has_ingredients,\n        'has_instructions': has_instructions,\n        'ingredient_count': ingredient_count,\n        'step_count': step_count,\n        'unique_word_ratio': unique_ratio,\n        'total_length': len(recipe_text)\n    }\n\n# Analyze examples\nprint(\"\\nAnalyzing generated recipes:\\n\")\nfor i, recipe in enumerate([recipe1, recipe2, recipe3], 1):\n    print(f\"Recipe {i} Analysis:\")\n    metrics = analyze_quality(recipe)\n    print(f\"  ✓ Has Ingredients: {metrics['has_ingredients']}\")\n    print(f\"  ✓ Has Instructions: {metrics['has_instructions']}\")\n    print(f\"  - Estimated ingredients: {metrics['ingredient_count']}\")\n    print(f\"  - Estimated steps: {metrics['step_count']}\")\n    print(f\"  - Unique word ratio: {metrics['unique_word_ratio']:.2f}\")\n    print(f\"  - Length: {metrics['total_length']} characters\")\n    print()\n\nprint(\"=\"*60)\nprint(\"Generation complete!\")\nprint(\"=\"*60)\n\n# Save improved examples\nexamples_data = {\n    'Recipe_Name': ['Chocolate Cake', 'Thai Green Curry', 'Healthy Breakfast Bowl'],\n    'Generated_Text': [recipe1, recipe2, recipe3],\n    'Temperature': [0.7, 0.85, 0.75]\n}\n\ndf_examples = pd.DataFrame(examples_data)\ndf_examples.to_csv('improved_recipe_examples.csv', index=False)\nprint(\"\\n✅ Saved improved examples to: improved_recipe_examples.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T22:06:42.661522Z","iopub.execute_input":"2025-11-03T22:06:42.662263Z","iopub.status.idle":"2025-11-03T22:07:06.725092Z","shell.execute_reply.started":"2025-11-03T22:06:42.662237Z","shell.execute_reply":"2025-11-03T22:07:06.724347Z"}},"outputs":[{"name":"stdout","text":"Loading fine-tuned model...\nModel loaded on cuda\n\n============================================================\nTESTING IMPROVED GENERATION\n============================================================\n\n--- Example 1: Chocolate Cake (Focused) ---\nRecipe: Chocolate Cake\nIngredients: cake mix, sugar and cocoa powder; eggs. Beat egg yolks with vanilla and 1/2 cup flour until light but not dry. Add powdered sugar to mixture mixing well. Pour batter into greased 9 x 13-inch pan. Bake at 350\\u00b0 for 45 minutes or till done when cool enough that cake can be used as a topping. Cool in pans on wire rack 10 minutes before cutting into squares. Makes 8 dozen (9\" x 12\") cookies.\nInstructions For baking: Mix together the first 4 ingredients then add them to pudding mix while still warm. In a small bowl combine cream cheese, lemon juice extract from pineapple chunks, chocolate chips & marshmallows. Stir gently all over thoroughly. Spread evenly around edges of pan top. Sprinkle with chopped pecans. Top with remaining whipped creme. Let stand 20 minutes covered before serving. Serves 6.\nIngredients : graham cracker crumbs, buttercream frosting icing, milk lite, strawberry jammer sprinkles , sour cherries sprinkle sugar\nInstructIONS FOR Baking: Melt margarine about 3 inches above center layer. Grease cookie sheet lightly with nonstick cooking spray. Line bottom halfwith parchment paper. Preheat oven 400\\w3p. Put cheesecake slices on top side by hand and bake 15 -20 min or possibly longer depending upon size cutouts. Cut onto thin strips after each minute to ensure consistency. Remove from oven 5 min prior adding confectioners' sugar. Place jelly roll sides down on prepared baking sheets. Roll out dough so it covers entire surface of baking sheet. Allow to cool completely . Drizzle with melted buttercream. Drop filling approximately 30-35 seconds apart if desired. Brush tops slightly with confectioner's sugar drippings. Cover bottoms of two 2-quart casseroles tightly with foil. Store chilled up to one week. Can also be refrigerated\n\n--- Example 2: Thai Curry (Creative) ---\nRecipe: Thai Green Curry\nIngredients: lime juice, sugar +, egg yolks, salt, curry powder/s, ground black pepper flakes, fresh gingerroot leaves seeds 1/2 cup jalapeno sauce, lemon juice, coconut milk, water\nInstructions: Combine the ingredients and stir well. Add it to a medium bowl. Put in refrigerator for at least 30 minutes. Make sure to let your spice mix stand before serving. The amount of spices is important! When ready take out the bowl and add the green curry paste (see note) and puree until smooth. Pour into glasses and chill 24 hours. Serve with your favorite vegetables like chicken or noodles. You can also serve with rice as a salad dressing on top along side these dishes which are delicious!\nIngredients vary depending how much you want your curry recipe. It's best if you put some leftover Jalapenos around so the flavors blend together even though you may not have used all of the veggies from the last dish. If I am going ahead this recipe will be very dry but we'll do our own testing now then :) Enjoy :)\nIngredients & Cooking Times: 4 servings\nInstruction: Mix remaining 2 tbsp jalapeño sauce, lime juice concentrate , lime juice cubes, coconut syrup etc. Stir constantly till combined. Taste carefully after each drink and adjust seasoning accordingly. Makes 6 quarts.\nIngredients = ketchup, vinegar, garlic oil, onion soup, chow mein noodles(I find them spicy), red curry paste*1/2 tsp turmeric powder**and other ingrediants added by way-wise since there's no need!! YUM!!!\nInstructION: Place everything except the reserved liquid mixture over your hot jars, fill the bottles up with water and store covered inside cool. Let rest overnight. This makes 12 quart sized containers that hold 5 cups and they look just like any normal jar. They keep warm while running wild....or possibly freeze too long\n\n--- Example 3: From Ingredients ---\nRecipe: Healthy Breakfast Bowl\nIngredients: oats, banana, honey, almonds, berries\nInstructions: 1. Beat together all ingredients except nuts and fruit. 2 Bake at 350° for about 20 minutes. 3 Serves 8.\nIngredients (makes 6 bowls): chocolate chips, cereal concentrate mix plus ground cinnamon powder; bananas 4. Crackers, cream cheese, pecans, vanilla ice cream 5., nuts 6-8 oz 7 cups water 8 eggs 9. salt\nInstruction(s) 10 Cook until just soft, stirring often 11 when cool 12 to 15 minutes. Cool completely before serving.\nInstructION FOR COLD BROTHING: 13 Mix remaining ingredients in bowl using a food processor or blender until smooth. 14 Stir constantly till creamy. Serve warm.\nNutrition Facts Serving Size: 28 servings Calories per 100g Fat Total Fat Sodium 275mg Carbohydrate 24g Protein 17g Calcium 25% Saturated Fat 0g Monounsaturated Fat Cholesterol 160mg 30% Sodium 50mg 40% Potassium 110mg 23% Total Carbohydrates 60g 32% Dietary Fiber 18g 31% Sugars 19g 21% Vitamin A 35 % Vitamin B 55 % Calcium 36 % Iron 16 % * Percent Daily Values are based on a 2000 calorie diet + http://www'taafield.com/calories/goldenfood-bowl/baseline-goldensnutritious - http\\u00b0\nIngredients Ingredients(d\n\n============================================================\nGENERATING VARIATIONS\n============================================================\n\nGenerating 3 variations for: Recipe: Vegetable Soup\nIngredients:\n\nVariation 1:\n----------------------------------------\nRecipe: Vegetable Soup\nIngredients: onion, celery stalk beef broth soup mix and water, mushrooms beans powder salt pepper\nInstructions: 1. In a large saucepan, heat the vegetable oil over medium-high heat. 2. Add the onion to pan; cook for 5 minutes, stirring occasionally, until soft but not browned on all sides (about 3 minutes). Remove from heat; add the rest of ingredients. Bring back to boil; simmer 10 minutes, or until liquid has reduced by half. Stir in the mushrooms if desired - cover with plastic wrap. Serve warm.\nRecipe Source: http://www'ta.com/recipes/?p=2430&s=1622 , http\\thttp:\\/forum_page/_topic%2Fc0&topics=-2770x1340&type=1&style=(text)&page=1 & link=paste&page=#!/forum %3A%2C%3Dwww's \"Recipes\" site www'The Recipes Forum! https://www .google.co.....catalog=posts&hl=en&ie=UTF8&qid=1074256550 #!/blog/#!/pages#recipes #Recipes #RECIPES AFFILIATE THE RECIPE SITE FOR FREE ONLINE AND STORE IN OUR CHINESE PROJECT OF YOUR CHOICE The Recipes Forums are NOT sponsored by Chow Yun FatCookies, Inc., nor do they endorse any individual brand of Chow YunFatCookied or its products. All recipes provided here are free access to our Cooking School at 4th Street Market High School(R), one block East of 12TH St NW, Washington, D2098. For additional information on how we can help you make your own delicious Chinese New Year's Eve meal check out our tips page about creating great dishes that will last as long before you take them off the ground. If you're\n\nVariation 2:\n----------------------------------------\nRecipe: Vegetable Soup\nIngredients: ground beef, onion soup mix, cream of mushroom soup, Worcestershire sauce and salt to taste (optional) Directions: 1. Mix all ingredients together in a bowl. 2-3 days later, add broth and mushrooms.\n 3 Toss well. 4 Cook 8 hours or until bubbly. 5 Serves 6.\nBatter can be made ahead for 10 minutes per package directions.\nIngredients are listed as follows: Salt & pepper to taste; may substitute buttermilk if desired .\nInstructions: 1.) Prepare your meat mixture by cutting into quarters with knife and pressing the tops down against the bone. Put it on a baking sheet lined lightly with paper towels. Sprinkle with remaining salt and pepper. Bake at 350° for 30 min. Then turn off oven and let stand 15 mins. Remove from pan and cool completely. When ready remove from oven. Add remaining flour and cook uncovered about 20minutes stirring occasionally. Serve warm topped with crackers and serve hot!\nIngredients listed as above: rice noodles , pasta cheese sandwiches etc., bread crumbs, cheddar cheese , butter cubes, frozen peas\nInstruction is not very clear cut up so read carefully before starting any kind research project like this one ! I think that my method will give you much better results without adding too many extra pieces since there are no real \"recipe\" recipes out there!! But we'll see how long they last :-) So enjoy :)\nIngredients as below: water, vegetable oil, cottage cheese, shredded cheese, milk - more delicious stuff :).\nInstructIONS: In a medium bowl combine dry ingredients, then stir in enough milk for thick batter. Place onto a cookie sheet lined baking sheet. Cover with foil and bake covered 25 min. Reduce oven temperature to 325°F then reduce oven to 350°C. Let rise again till heated through. Cool thoroughly then roll over to prevent burning. Store wrapped tightly closed inside refrigerator sealed\n\nVariation 3:\n----------------------------------------\nRecipe: Vegetable Soup\nIngredients: tomatoes, onion soup mix(soy sauce) sugar vinegar vinegar, cayenne pepper salt, garlic powder, ground coriander, red pepper flakes cook, boiling water, chicken broth, mushrooms, potatoes bouillon cubes leeks parsley salt water pepper cooking spray vegetable broth in microwave for 30 seconds stirring constantly. Stir in 1 teaspoon salt and 3/4 cup can of broth (this can be frozen). Cook the soup until thickened and browned. Add a little oil or stock to taste; season with black pepper flakes. Sprinkle with chopped fresh thyme leaves if desired added a couple teaspoons of dried oregano. Simmer covered about 5 minutes stirring occasionally. Serve over rice or steamed vegetables during warm days. *This is one extra ingredient that I may have on hand but only so you get an additional serving option! This soup takes place at 8 am per week using 6 cans of beer every day from 4 pm to 10 PM. If you'd like it all your favorite flavors will run down!! It's not too heavy as most soups make use of some ingredients just before they boil add another handful. Very delicious when served hot without refrigeration :) Enjoy!\nIngredients are listed under \"Nutritional Information\" below. All directions refer mainly towards veggie options including meat broth and carrots along side bread crumbs. The veggies cover any other portion of the dish completely except for the mashed potatoes which does NOT fit into this order. Any leftover juice has been used heretofore then stored safely . When ready replace meat with rice slices topped by beef buns ! NOTE: Just because you dont want any other flavor than rice doesnt mean that you cant enjoy this recipe!!! You'll probably find some way around this last part - adding more milk works better after adding more liquid :-) \nIngredients include sausage gravy, mustard seed flour tortillas stuffed cheese pieces , shredded chicken breasts cooked cooked rice, white wine, olives, pecan\n\n\n============================================================\nQUALITY ANALYSIS\n============================================================\n\nAnalyzing generated recipes:\n\nRecipe 1 Analysis:\n  ✓ Has Ingredients: True\n  ✓ Has Instructions: False\n  - Estimated ingredients: 3\n  - Estimated steps: 0\n  - Unique word ratio: 0.83\n  - Length: 1805 characters\n\nRecipe 2 Analysis:\n  ✓ Has Ingredients: True\n  ✓ Has Instructions: True\n  - Estimated ingredients: 5\n  - Estimated steps: 0\n  - Unique word ratio: 0.83\n  - Length: 1828 characters\n\nRecipe 3 Analysis:\n  ✓ Has Ingredients: True\n  ✓ Has Instructions: True\n  - Estimated ingredients: 5\n  - Estimated steps: 0\n  - Unique word ratio: 0.88\n  - Length: 1195 characters\n\n============================================================\nGeneration complete!\n============================================================\n\n✅ Saved improved examples to: improved_recipe_examples.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Create a zip file of the model\nimport shutil\nshutil.make_archive('recipe-gpt2-final', 'zip', './recipe-gpt2-final')\n\n# Download - ADD THIS LINE\nfrom IPython.display import FileLink\nFileLink('recipe-gpt2-final.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T22:11:08.474063Z","iopub.execute_input":"2025-11-03T22:11:08.474713Z","iopub.status.idle":"2025-11-03T22:11:33.625734Z","shell.execute_reply.started":"2025-11-03T22:11:08.474690Z","shell.execute_reply":"2025-11-03T22:11:33.625098Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/recipe-gpt2-final.zip","text/html":"<a href='recipe-gpt2-final.zip' target='_blank'>recipe-gpt2-final.zip</a><br>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}